1. Why do you think companies analyze large volumes of data?

Analizing large amounts of data gives them opportunity to more precisely predict the future for their projects, hence enhancing overall company income.
That to be said more data leads to more reliable predictions.

2. If analyzing and sorting large data manually in Excel is difficult, how do you think Python can help solve this problem?

with python we could automate the process of data cleaning, inserting, or even combining and checking which product is more needed and not.

3. Imagine you work at a sales company that receives data about 10,000 customer transactions daily. How would you analyze this data?

First i would store data in a database (e.g. PostgreSQL). Then clean data using Pandas (handle nulls, fix types). 
Group and summarize (e.g. total sales, top products). Analyze trends over time. Segment customers with clustering. 
lastly Visualize with Seaborn/Plotly.


4. In your opinion, what tasks can Python be useful for in BI processes? (e.g., data cleaning, visualization, etc.)

Python helps with data cleaning, extraction, analysis, visualization, and automation in BI processes.

5. If you wanted to compare a company's profit year by year, how could this be done using Python?

Iâ€™d group profit data by year in Pandas and visualize it with a bar chart to compare performance.

6. If you don't know Python, what difficulties might you face when working with large datasets?

Without Python, handling large datasets is slow, error-prone, and lacks automation or deep analysis.